{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pinecone import Pinecone\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "class PineconeRAG:\n",
    "    \"\"\"Handles RAG operations using Pinecone vector database\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize PineconeRAG with necessary credentials and settings\n",
    "\n",
    "        Args:\n",
    "            pinecone_api_key: Pinecone API key\n",
    "            environment: Pinecone environment\n",
    "            index_name: Name of the Pinecone index to use\n",
    "            openai_api_key: OpenAI API key for generating embeddings\n",
    "        \"\"\"\n",
    "        self.pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "        self.index_name = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "        self.openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        self.openai_client = OpenAI(api_key=self.openai_api_key)\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        \"\"\"Initialize Pinecone client and connect to index\"\"\"\n",
    "        pc = Pinecone(api_key=self.pinecone_api_key, region=\"us-east-1\")\n",
    "        self.index = pc.Index(self.index_name)\n",
    "\n",
    "    def chunk_text(self, text: str, chunk_size: int = 500) -> List[str]:\n",
    "        \"\"\"\n",
    "        Split text into chunks of approximately equal size\n",
    "\n",
    "        Args:\n",
    "            text: Text to split into chunks\n",
    "            chunk_size: Target size of each chunk in words\n",
    "\n",
    "        Returns:\n",
    "            List of text chunks\n",
    "        \"\"\"\n",
    "        words = text.split()\n",
    "        chunks = []\n",
    "\n",
    "        for i in range(0, len(words), chunk_size):\n",
    "            chunk = \" \".join(words[i : i + chunk_size])\n",
    "            chunks.append(chunk)\n",
    "\n",
    "        return chunks\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts using OpenAI's API\n",
    "\n",
    "        Args:\n",
    "            texts: List of text strings to generate embeddings for\n",
    "\n",
    "        Returns:\n",
    "            List of embedding vectors\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.openai_client.embeddings.create(\n",
    "                model=\"text-embedding-3-small\", input=texts\n",
    "            )\n",
    "            return [data.embedding for data in response.data]\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error generating embeddings: {str(e)}\")\n",
    "\n",
    "    def upsert_documents(\n",
    "        self,\n",
    "        documents: List[str],\n",
    "        metadata: Optional[List[dict]] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Upsert documents and their embeddings into Pinecone\n",
    "\n",
    "        Args:\n",
    "            documents: List of document strings\n",
    "            embeddings: List of embedding vectors for each document\n",
    "            metadata: Optional list of metadata dicts for each document\n",
    "        \"\"\"\n",
    "        # Process each document into chunks\n",
    "        all_chunks = []\n",
    "        chunk_metadata = []\n",
    "\n",
    "        for i, doc in enumerate(documents):\n",
    "            chunks = self.chunk_text(doc)\n",
    "            all_chunks.extend(chunks)\n",
    "\n",
    "            # Replicate metadata for each chunk if provided\n",
    "            if metadata:\n",
    "                chunk_metadata.extend([metadata[i]] * len(chunks))\n",
    "\n",
    "        # Generate embeddings for all chunks\n",
    "        embeddings = self.generate_embeddings(all_chunks)\n",
    "\n",
    "        if metadata and len(chunk_metadata) != len(all_chunks):\n",
    "            raise ValueError(\"Metadata length must match number of chunks\")\n",
    "\n",
    "        vectors = []\n",
    "        for i, (chunk, emb) in enumerate(zip(all_chunks, embeddings)):\n",
    "            vector = {\n",
    "                \"id\": f\"doc_{i}\",\n",
    "                \"values\": emb,\n",
    "                \"metadata\": {\n",
    "                    \"text\": chunk,\n",
    "                    **(chunk_metadata[i] if chunk_metadata else {}),\n",
    "                },\n",
    "            }\n",
    "            vectors.append(vector)\n",
    "\n",
    "        self.index.upsert(vectors=vectors)\n",
    "\n",
    "    def query(self, query_embedding: List[float], top_k: int = 5) -> List[str]:\n",
    "        \"\"\"\n",
    "        Query Pinecone index with embedding vector\n",
    "\n",
    "        Args:\n",
    "            query_embedding: Embedding vector for the query\n",
    "            top_k: Number of results to return\n",
    "\n",
    "        Returns:\n",
    "            List of matched document strings\n",
    "        \"\"\"\n",
    "        results = self.index.query(\n",
    "            vector=query_embedding, top_k=top_k, include_metadata=True\n",
    "        )\n",
    "\n",
    "        # Extract document texts from results\n",
    "        documents = []\n",
    "        for match in results.matches:\n",
    "            if match.metadata and \"text\" in match.metadata:\n",
    "                documents.append(match.metadata[\"text\"])\n",
    "\n",
    "        return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_c = PineconeRAG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
